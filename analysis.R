
### (1) Loading the required R packages ------------------------------------ ###

library(RCurl)
library(XML)
library(stringr)

### (2) Grabbing information from the web page ----------------------------- ###

url <- "http://www.letpub.com.cn/index.php?journalid=15&page=journalapp&view=detail"
cont <- getURL(url)

# Extracting the journal name. 
con.tree <- htmlTreeParse(cont)
doc <- con.tree$children$html
# node <- getNodeSet(doc, "//div[@id='link_list']")
node <- getNodeSet(doc, "//div[@id='link_list']/a")
content <- sapply(node, xmlValue)[3]
content <- gsub(" ??????", "", content)

# Extracting other items. 
tabs <- readHTMLTable(cont)
inf.tab <- tabs[[4]]

# ??????ISSN
# E-ISSN
# 2022-2023??????????????????
# ??????????????????
# 2022-2023????????? 
# ??????????????????
# h-index
# CiteScore
# ??????????????????
# ??????????????????
# ??????OA????????????
# ?????????
# ?????????????????????
# ????????????
# ????????????
# ????????????
# ????????????
# Gold OA????????????
# WOS??????SCI?????? ( 2022-2023????????????)
# ?????????SCI????????????( 2022???12??????????????????)

loc.22s <- grep("2022???12??????????????????", inf.tab$V1)

#. grep("????????????", inf.tab$V2)
#. grep("????????????", inf.tab$V2)

fenqu.2022s <- tabs[[8]]
fenqu.2021j <- tabs[[10]]
fenqu.2021s <- tabs[[12]]
fenqu.2020s <- tabs[[14]]


